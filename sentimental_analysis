%pip install wordcloud
 
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))
 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
from wordcloud import WordCloud
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
import pickle
import re
 
data = pd.read_csv(r"/content/amazon_alexa.tsv", delimiter = '\t', quoting = 3)
print(f"Dataset shape : {data.shape}")
 
print(f"Feature Value : {data.columns.values}")
 
data.isnull().sum()
 
data.dropna(inplace=True)
 
data['length'] = data['verified_reviews'].apply(len)
 
 
data.head()
 
data['rating'].value_counts().plot.bar(color='red')
plt.title('Rating Distribution Count')
plt.xlabel('Rating')
plt.ylabel('Count')
plt.show()
 
fig = plt.figure(figsize=(7,7))
 
colors = ('red', 'green', 'blue','orange','yellow')
 
wp = {'linewidth':1, "edgecolor":'black'}
 
tags = data['rating'].value_counts()/data.shape[0]
 
explode=(0.1,0.1,0.1,0.1,0.1)
 
tags.plot(kind='pie', autopct="%1.1f%%", shadow=True, colors=colors, startangle=90, wedgeprops=wp, explode=explode, label='Percentage wise distrubution of rating')
 
from io import  BytesIO
 
graph = BytesIO()
 
fig.savefig(graph, format="png")
 
